https://www.researchgate.net/post/The_choice_of_post-hoc_test

ANOVA is not interesting (and sensible) at all when you anyway want to compare individual groups. ANOVA is only relevant to asses the impact of a predictor (or a set of predictors) in a more complex model. It is only very, very indirectly and marginally related to the question if expected values differ between levels of a categorical predictor. Almost all post-hoc tests control the FWER independent of the ANOVA, and the "two-step-procedure" (first check ANOVA, then do post-hoc-tests) leads to additional problems.Note that "post-hoc" doe not mean "after ANOVA" but "after knowing the data (of the other groups)". This is often misinterpreted in many textbooks.
To my experience, differences between the different post-hoc tests are very "academic" and typically of only little practical relevance. Practically, there are only two tests I consider:
Tukey's HSD for all-pairwise comparisons and
Dunnett's procedure for multiple-to-one comparisons.
They are quite generally applicable and have no severe problems (as far as I know). Dunnett is superior for multiple-to-one comparisons, because Tukey assumes that k*(k-1) tests are performed (each of which can produce a false positive result) whereas Dunnett's procedure has to consider only k-1 tests (k is the number of groups).
There is an intermediate between Tukey and Dunnett: Hsuâ€™s multiple comparisons with best (MCB). This test is like Dunnett's test but without a defined control group. This test first determines the "control group" as the "best group", which is the group with the most extreme mean and then compared all other groups to this one. It thus makes (k-1) tests (better than Tukey) but first has to determine the "best", what is negatively affecting the FWER (worse than Dunnett). (Note that selecting the "best" group by eye and then do Dunnett's test irgnores the uncertainty associated with the selection of the "best" group, so the FWER is not really controlled then).
If I test only very few and specific pairs of many possible pairs, I prefer Holm adjustments to control the FWER. This can outperform Tukey's test w.r.t. power.
For screenings it is often more sensible to control the FDR, what is done by the procedure of Benjamini/Hochberg.
However, in research it is more important - to my opinion - to think if and what error rate should be reasonably controlled at what level. The rather mindless control of a FWER at 5% is quite stupid, although typical...
